{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.movies import get_movie_script\n",
    "from src.storyboard_generator import StoryboardGenerator\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script, characters = get_movie_script(\"godfather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INT DAY: DON'S OFFICE (SUMMER 1945)\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tACT LIKE A MAN!  By Christ in\n",
      "\t\tHeaven, is it possible you turned\n",
      "\t\tout no better than a Hollywood\n",
      "\t\tfinocchio.\n",
      "\n",
      "\tBoth HAGEN and JOHNNY cannot refrain from laughing.  The DON\n",
      "\tsmiles.  SONNY enters as noiselessly as possible, still\n",
      "\tadjusting his clothes.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tAll right, Hollywood...Now tell me\n",
      "\t\tabout this Hollywood Pezzonovanta\n",
      "\t\twho won't let you work.\n",
      "\n",
      "\t\t\t\tJOHNNY\n",
      "\t\tHe owns the studio.  Just a month\n",
      "\t\tago he bought the movie rights to\n",
      "\t\tthis book, a best seller.  And the\n",
      "\t\tmain character is a guy just like\n",
      "\t\tme.  I wouldn't even have to act,\n",
      "\t\tjust be myself.\n",
      "\n",
      "\tThe DON is silent, stern.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tYou take care of your family?\n",
      "\n",
      "\t\t\t\tJOHNNY\n",
      "\t\tSure.\n",
      "\n",
      "\tHe glances at SONNY, who makes himself as inconspicuous as\n",
      "\the can.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tYou look terrible.  I want you to\n",
      "\t\teat well, to rest.  And spend time\n",
      "\t\twith your family.  And then, at the\n",
      "\t\tend of the month, this big shot\n",
      "\t\twill give you the part you want.\n",
      "\n",
      "\t\t\t\tJOHNNY\n",
      "\t\tIt's too late.  All the contracts\n",
      "\t\thave been signed, they're almost\n",
      "\t\tready to shoot.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tI'll make him an offer he can't\n",
      "\t\trefuse.\n",
      "\n",
      "\tHe takes JOHNNY to the door, pinching his cheek hard enough\n",
      "\tto hurt.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tNow go back to the party and leave\n",
      "\t\tit to me.\n",
      "\n",
      "\tHe closes the door, smiling to himself.  Turns to HAGEN.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tWhen does my daughter leave with\n",
      "\t\ther bridegroom?\n",
      "\n",
      "\t\t\t\tHAGEN\n",
      "\t\tThey'll cut the cake in a few\n",
      "\t\tminutes...leave right after that.\n",
      "\t\tYour new son-in-law, do we give him\n",
      "\t\tsomething important?\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tNo, give him a living.  But never\n",
      "\t\tlet him know the family's business.\n",
      "\t\tWhat else, Tom?\n",
      "\n",
      "\t\t\t\tHAGEN\n",
      "\t\tI've called the hospital; they've\n",
      "\t\tnotified Consiglere Genco's family\n",
      "\t\tto come and wait.  He won't last\n",
      "\t\tout the night.\n",
      "\n",
      "\tThis saddens the DON.  He sighs.\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tGenco will wait for me.  Santino,\n",
      "\t\ttell your brothers they will come\n",
      "\t\twith me to the hospital to see\n",
      "\t\tGenco.  Tell Fredo to drive the big\n",
      "\t\tcar, and ask Johnny to come with us.\n",
      "\n",
      "\t\t\t\tSONNY\n",
      "\t\tAnd Michael?\n",
      "\n",
      "\t\t\t\tDON CORLEONE\n",
      "\t\tAll my sons.\n",
      "\t\t\t  (to HAGEN)\n",
      "\t\tTom, I want you to go to California\n",
      "\t\ttonight.  Make the arrangements.\n",
      "\t\tBut don't leave until I come back\n",
      "\t\tfrom the hospital and speak to you.\n",
      "\t\tUnderstood?\n",
      "\n",
      "\t\t\t\tHAGEN\n",
      "\t\tUnderstood.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = StoryboardGenerator(script, characters_dict, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.generate_and_save(save_dir=\"unique\", generation_type=\"unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.generate_and_save(save_dir=\"prompt_weights\", generation_type=\"prompt_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.generate_and_save(save_dir=\"modified-cfg\", generation_type=\"modified-cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Comments on Modified Classifier-Free Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Unconditional Pass + Multiple Conditional Passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\hat{\\epsilon}_{\\text{cond\\_combined}}=\\frac{1}{\\sum_{i=1}^nw_i}\\sum_{i=1}^nw_i\\hat{\\epsilon}_{\\text{cond}_i}$\n",
    "where we have one pass per subprompt to get $\\hat{\\epsilon}_{\\text{cond}_i}$ and $n$ is the number of subprompts.\n",
    "Then the classifier free guidance with scale $g$ is $$\\hat{\\epsilon}=\\hat{\\epsilon}_{\\text{uncond}}+g(\\hat{\\epsilon}_{\\text{cond\\_combined}}-\\hat{\\epsilon}_{\\text{uncond}})$$\n",
    "where we have one unconditional pass at each step to get $\\hat{\\epsilon}_{\\text{uncond}}$\n",
    "\n",
    "- Total UNet calls per step: $1+n$\n",
    "- Each subprompt has a relative weight but they all share the same baseline unconditional pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Unconditional Passes (One per Subprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $$\\hat{\\epsilon}=\\hat{\\epsilon}_{\\text{uncond}}+g\\sum_{i=1}^nw_i(\\hat{\\epsilon}_{\\text{cond}_i}-\\hat{\\epsilon}_{\\text{uncond}_i})$$\n",
    "- Total UNet calls per step: $1+2n$ (One global unconditional + two passes for each subprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiPromptPipelineApproach2(StableDiffusionPipeline):\n",
    "#     \"\"\"\n",
    "#     Multi-Prompt CFG with MULTIPLE unconditional passes:\n",
    "#       - 1 global unconditional pass per step: e_uncond\n",
    "#       - For each subprompt i:\n",
    "#           e_uncond_i (subprompt-specific unconditional)\n",
    "#           e_cond_i    (subprompt conditional)\n",
    "#       - Combine: e = e_uncond + g * sum_i[ w_i * ( e_cond_i - e_uncond_i ) ]\n",
    "#     \"\"\"\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def __call__(\n",
    "#         self,\n",
    "#         global_uncond_embeds: torch.Tensor,\n",
    "#         subprompt_pairs: list[tuple[torch.Tensor, torch.Tensor]],\n",
    "#         subprompt_weights: list[float],\n",
    "#         guidance_scale: float = 7.5,\n",
    "#         height: int = 512,\n",
    "#         width: int = 512,\n",
    "#         num_inference_steps: int = 50,\n",
    "#         generator: torch.Generator = None,\n",
    "#         latents: torch.Tensor = None,\n",
    "#         output_type: str = \"pil\",\n",
    "#         return_dict: bool = True,\n",
    "#         **kwargs\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             global_uncond_embeds (Tensor): [batch, seq_len, hidden_dim] for the entire prompt's unconditional pass.\n",
    "#             subprompt_pairs (list of (uncond_i, cond_i)):\n",
    "#                 Each element is a tuple: (uncond_embeds_i, cond_embeds_i).\n",
    "#             subprompt_weights (list[float]): Weights w_i for each subprompt i.\n",
    "#         \"\"\"\n",
    "#         device = self._execution_device\n",
    "#         batch_size = global_uncond_embeds.shape[0]\n",
    "#         num_subprompts = len(subprompt_pairs)\n",
    "\n",
    "#         if num_subprompts != len(subprompt_weights):\n",
    "#             raise ValueError(\"subprompt_pairs and subprompt_weights must have the same length.\")\n",
    "\n",
    "#         # 1. Validate or fallback to default\n",
    "#         if not height or not width:\n",
    "#             height, width = self._default_height_width()\n",
    "\n",
    "#         # 2. Scheduler timesteps\n",
    "#         self.scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "#         timesteps = self.scheduler.timesteps\n",
    "\n",
    "#         # 3. Prepare latents\n",
    "#         if latents is None:\n",
    "#             shape = (batch_size, self.unet.config.in_channels, height // 8, width // 8)\n",
    "#             latents = torch.randn(shape, generator=generator, device=device, dtype=global_uncond_embeds.dtype)\n",
    "#             latents = latents * self.scheduler.init_noise_sigma\n",
    "#         else:\n",
    "#             latents = latents.to(device)\n",
    "\n",
    "#         # 4. Diffusion loop\n",
    "#         for i, t in enumerate(timesteps):\n",
    "#             latent_model_input = self.scheduler.scale_model_input(latents, t)\n",
    "\n",
    "#             # (A) Single global unconditional pass\n",
    "#             e_uncond_global = self.unet(\n",
    "#                 latent_model_input, t, encoder_hidden_states=global_uncond_embeds, **kwargs\n",
    "#             ).sample\n",
    "\n",
    "#             # (B) For each subprompt: unconditional + conditional\n",
    "#             sub_deltas = []\n",
    "#             for (uncond_i, cond_i), w in zip(subprompt_pairs, subprompt_weights):\n",
    "#                 e_uncond_i = self.unet(latent_model_input, t, encoder_hidden_states=uncond_i, **kwargs).sample\n",
    "#                 e_cond_i = self.unet(latent_model_input, t, encoder_hidden_states=cond_i, **kwargs).sample\n",
    "\n",
    "#                 # Delta for subprompt i\n",
    "#                 delta_i = w * (e_cond_i - e_uncond_i)\n",
    "#                 sub_deltas.append(delta_i)\n",
    "\n",
    "#             # (C) Combine sub-deltas\n",
    "#             sum_deltas = sum(sub_deltas)  # sum_i w_i ( e_cond_i - e_uncond_i )\n",
    "\n",
    "#             # (D) Final output\n",
    "#             guided_out = e_uncond_global + guidance_scale * sum_deltas\n",
    "\n",
    "#             # (E) Scheduler step\n",
    "#             latents = self.scheduler.step(guided_out, t, latents, **kwargs).prev_sample\n",
    "\n",
    "#         # 5. Decode\n",
    "#         if output_type == \"latent\":\n",
    "#             if return_dict:\n",
    "#                 from diffusers.pipelines.stable_diffusion.pipeline_output import StableDiffusionPipelineOutput\n",
    "#                 return StableDiffusionPipelineOutput(images=latents, nsfw_content_detected=None)\n",
    "#             return latents\n",
    "\n",
    "#         image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n",
    "#         image = self.image_processor.postprocess(image, output_type=output_type)\n",
    "\n",
    "#         if return_dict:\n",
    "#             from diffusers.pipelines.stable_diffusion.pipeline_output import StableDiffusionPipelineOutput\n",
    "#             return StableDiffusionPipelineOutput(images=image, nsfw_content_detected=None)\n",
    "#         return image\n",
    "\n",
    "# print(\"Loading Approach 2 pipeline...\")\n",
    "# pipe2 = MultiPromptPipelineApproach2.from_pretrained(\n",
    "#     \"runwayml/stable-diffusion-v1-5\",\n",
    "#     torch_dtype=torch.float16\n",
    "# ).to(\"cuda\")\n",
    "# pipe2.scheduler = UniPCMultistepScheduler.from_config(pipe2.scheduler.config)\n",
    "# pipe2.enable_model_cpu_offload()\n",
    "# pipe2.enable_attention_slicing()\n",
    "\n",
    "#### EXAMPLE\n",
    "# # Suppose we want environment and style separately\n",
    "# global_uncond = encode_subprompt(pipe2, \"\")  # global unconditional\n",
    "# env_uncond = encode_subprompt(pipe2, \"\")     # unconditional for environment\n",
    "# env_cond   = encode_subprompt(pipe2, \"ancient forest, misty atmosphere\")\n",
    "# style_uncond = encode_subprompt(pipe2, \"\")   # unconditional for style\n",
    "# style_cond   = encode_subprompt(pipe2, \"cinematic style, high contrast\")\n",
    "\n",
    "# # subprompt_pairs = [ (uncond_env, cond_env), (uncond_style, cond_style) ]\n",
    "# subprompt_pairs_2 = [\n",
    "#     (env_uncond, env_cond),\n",
    "#     (style_uncond, style_cond)\n",
    "# ]\n",
    "\n",
    "# weights_2 = [1.5, 1.8]\n",
    "# print(\"Generating image with Approach 2 (multiple unconditional passes)...\")\n",
    "# output2 = pipe2(\n",
    "#     global_uncond_embeds=global_uncond,\n",
    "#     subprompt_pairs=subprompt_pairs_2,\n",
    "#     subprompt_weights=weights_2,\n",
    "#     guidance_scale=7.5,\n",
    "#     num_inference_steps=25\n",
    "# )\n",
    "# output2.images[0].save(\"approach2_result.png\")\n",
    "# print(\"Saved approach2_result.png\")\n",
    "\n",
    "# def generate_and_save_images_multi_prompt2(scenes, characters_dict, pipe, save_dir, device,\n",
    "#                                              num_inference_steps=50, guidance_scale=7.5):\n",
    "#     \"\"\"\n",
    "#     Generate images for each scene using Multi-Prompt Approach 2 (multiple unconditional passes)\n",
    "#     and save each image to the specified directory.\n",
    "    \n",
    "#     Args:\n",
    "#         scenes (list): List of scene objects (each scene is a dict).\n",
    "#         characters_dict (dict): Dictionary of character descriptions.\n",
    "#         pipe: The MultiPromptPipelineApproach2 pipeline instance.\n",
    "#         save_dir (str): Directory where images will be saved.\n",
    "#         device (str): Device to use (e.g., \"cuda\" or \"cpu\").\n",
    "#         num_inference_steps (int, optional): Number of diffusion steps.\n",
    "#         guidance_scale (float, optional): Guidance scale for classifier-free guidance.\n",
    "        \n",
    "#     Returns:\n",
    "#         list: List of generated PIL.Image objects.\n",
    "#     \"\"\"\n",
    "#     import os\n",
    "#     import torch\n",
    "\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     generated_images = []\n",
    "\n",
    "#     for i, scene in enumerate(scenes):\n",
    "#         # Get subprompt texts and corresponding weights for the scene.\n",
    "#         subprompt_texts, subprompt_weights = scenes_to_formatted_prompts([scene], characters_dict)[0]\n",
    "\n",
    "#         # Encode the global unconditional prompt once.\n",
    "#         global_uncond_embeds = encode_subprompt(pipe, \"\", device=device)\n",
    "\n",
    "#         # For each subprompt, encode a pair: (unconditional, conditional)\n",
    "#         subprompt_pairs = []\n",
    "#         for sp in subprompt_texts:\n",
    "#             uncond_i = encode_subprompt(pipe, \"\", device=device)\n",
    "#             cond_i = encode_subprompt(pipe, sp, device=device)\n",
    "#             subprompt_pairs.append((uncond_i, cond_i))\n",
    "\n",
    "#         print(f\"Generating image for scene {i+1} using Approach 2...\")\n",
    "#         with torch.no_grad():\n",
    "#             output = pipe(\n",
    "#                 global_uncond_embeds=global_uncond_embeds,\n",
    "#                 subprompt_pairs=subprompt_pairs,\n",
    "#                 subprompt_weights=subprompt_weights,\n",
    "#                 guidance_scale=guidance_scale,\n",
    "#                 num_inference_steps=num_inference_steps\n",
    "#             )\n",
    "#         generated_image = output.images[0]\n",
    "#         generated_images.append(generated_image)\n",
    "#         image_path = os.path.join(save_dir, f\"scene_{i+1}_approach2.png\")\n",
    "#         generated_image.save(image_path)\n",
    "#         print(f\"Image {i+1} saved to {image_path}\")\n",
    "\n",
    "#     return generated_images\n",
    "\n",
    "# # Example usage:\n",
    "# save_directory = \"stories/multi_prompt_approach2\"\n",
    "# generated_images = generate_and_save_images_multi_prompt2(scenes, characters_dict, pipe2, save_directory, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped this because it's extremely slow (20 min for one image) and it's not good either."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl-ecole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
