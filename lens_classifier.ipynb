{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset with images and labels from the pure set of videos and the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import process_all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_ROOT = \"C:\\\\Users\\\\sandr\\\\Downloads\\\\trailer\\\\trailer\" # Path to the root of the video files\n",
    "JSON_PATH = \"C:\\\\Users\\\\sandr\\\\Downloads\\\\v1_split_trailer.json\" # Path to the json file containing the data information\n",
    "IMAGE_QUALITY = 15\n",
    "OUTPUT_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrac_data = False\n",
    "if extrac_data:\n",
    "    process_all_splits(VIDEO_ROOT, JSON_PATH, IMAGE_QUALITY, OUTPUT_DIR) # took 1h and 8 minutes with â‰ˆ8frames/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data import LensTypeDataset\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "noise_stds = [0.05, 0.1, 0.2, 0.4, 0.5]\n",
    "noise_percentage = 0.3\n",
    "\n",
    "train_dataset = LensTypeDataset(root_dir=\"./data\", split=\"train\", transform=transform_train,\n",
    "                                noisy_percentage=noise_percentage, noise_stds=noise_stds, seed=SEED)\n",
    "val_dataset = LensTypeDataset(root_dir=\"./data\", split=\"val\", transform=transform_val, noisy_percentage=0.0)\n",
    "test_dataset = LensTypeDataset(root_dir=\"./data\", split=\"test\", transform=transform_val, noisy_percentage=0.0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Images in train: {len(train_dataset)}\")\n",
    "print(f\"Images in val: {len(val_dataset)}\")\n",
    "print(f\"Images in test: {len(test_dataset)}\")\n",
    "print(f\"Total number of images: {len(test_dataset) + len(val_dataset) + len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train label count: {Counter(train_dataset.labels)}\")\n",
    "print(f\"Val label count: {Counter(val_dataset.labels)}\")\n",
    "print(f\"Test label count: {Counter(test_dataset.labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "fig.suptitle(\"Sample Images from Train Dataset\", fontsize=14)\n",
    "\n",
    "label_mapping = {0: \"ECS\", 1: \"CS\", 2: \"MS\", 3: \"FS\", 4: \"LS\"}\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images[i].permute(1, 2, 0).numpy()  # (C, H, W) to (H, W, C)\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Label: {label_mapping[labels[i].item()]}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "    print(f\"Train Loss: {avg_loss:.4f}, Train Accuracy: {acc:.4f}\")\n",
    "\n",
    "    return avg_loss, acc\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f\"Val Loss: {avg_loss:.4f}, Val Accuracy: {acc:.4f}\")\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters:\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)\n",
    "    dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
    "    \n",
    "    # Build the model: Fine-tune EfficientNetB3 (only classifier parameters are trainable)\n",
    "    model = models.efficientnet_b3(pretrained=True)\n",
    "    # Freeze all layers except the classifier\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    in_feats = model.classifier[1].in_features  # e.g., 1536\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_feats, 512),\n",
    "        nn.SiLU(inplace=True),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(512, 5)\n",
    "    )\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss, optimizer, and scheduler.\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # Using CosineAnnealingLR; adjust T_max as needed (here we set T_max equal to number of epochs)\n",
    "    epochs_optuna = 3  # training for 3 epochs for speed during hyperparameter search\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs_optuna)\n",
    "    \n",
    "    # Train for a few epochs\n",
    "    for epoch in range(epochs_optuna):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, epoch)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Here we return the validation loss as the objective.\n",
    "    # (Optuna minimizes by default, and a lower validation loss indicates better performance.)\n",
    "    return val_loss\n",
    "\n",
    "# Create an Optuna study to minimize the objective (validation loss)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print the best hyperparameters found.\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training with best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best hyperparameters from the Optuna study (assume study.best_trial.params exists)\n",
    "best_hyperparams = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"best_hyperparams.json\", \"w\") as f:\n",
    "    json.dump(best_hyperparams, f)\n",
    "print(\"Best hyperparameters saved.\")\n",
    "\n",
    "# Later, load the hyperparameters\n",
    "with open(\"best_hyperparams.json\", \"r\") as f:\n",
    "    best_hyperparams = json.load(f)\n",
    "print(\"Best hyperparameters loaded:\", best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm  # Ensure tqdm is imported\n",
    "\n",
    "# Build the model using EfficientNetB3 as in your fine-tuning code\n",
    "model = models.efficientnet_b3(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "in_feats = model.classifier[1].in_features  # e.g., 1536\n",
    "\n",
    "# Use the best hyperparameters for dropout, learning rate, and weight decay.\n",
    "# If a hyperparameter is missing in the JSON file, we set a default.\n",
    "dropout_rate = best_hyperparams.get(\"dropout_rate\", 0.3)\n",
    "lr = best_hyperparams.get(\"lr\", 3e-4)\n",
    "weight_decay = best_hyperparams.get(\"weight_decay\", 1e-4)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_feats, 512),\n",
    "    nn.SiLU(inplace=True),\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(512, 5)\n",
    ")\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function, optimizer, and learning rate scheduler.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# Soft early stopping parameters\n",
    "patience = 10\n",
    "min_improvement = 0.001  # minimal decrease in validation loss to be considered an improvement\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "epochs_no_improve = 0\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, epoch)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Check if validation loss has improved by at least the minimal threshold.\n",
    "    if best_val_loss - val_loss > min_improvement:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        print(\"Validation loss improved. Model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No significant improvement for {epochs_no_improve} epochs.\")\n",
    "    \n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights (i.e. those from the epoch with the best validation loss)\n",
    "model.load_state_dict(best_model_wts)\n",
    "# Save the final model weights to disk.\n",
    "torch.save(model.state_dict(), \"final_guidance_classifier.pth\")\n",
    "print(\"Final model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced finetung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ **Key Techniques Used**\n",
    "\n",
    "1. **Hyperparameter Optimization (Optuna)**  \n",
    "   - Automated the search for optimal hyperparameters like hidden layer dimension, learning rate, weight decay, dropout, and batch size.  \n",
    "   - Improves model performance without manual trial-and-error.\n",
    "\n",
    "2. **Advanced Data Augmentation**  \n",
    "   - **CutMix:** Enhances generalization by mixing images and labels, making the model robust to occlusions and mixed features.  \n",
    "   - **Noise Injection:** Simulates diffusion process noise to train the classifier on noisy images, aligning with the guidance objective.\n",
    "\n",
    "3. **Mixed Precision Training (AMP)**  \n",
    "   - Reduces memory usage and speeds up training while maintaining accuracy through 16-bit floating point computations.  \n",
    "\n",
    "4. **Stochastic Weight Averaging (SWA)**  \n",
    "   - Averages weights over training epochs, improving generalization and stability of the model.\n",
    "\n",
    "5. **Learning Rate Scheduling (CosineAnnealingLR & SWALR)**  \n",
    "   - Adjusts learning rate dynamically to escape local minima and improve convergence.\n",
    "\n",
    "6. **Soft Early Stopping**  \n",
    "   - Monitors validation accuracy and halts training when improvements stagnate, preventing overfitting.\n",
    "\n",
    "7. **Model & Hyperparameter Saving**  \n",
    "   - Saves the best model and hyperparameters for reproducibility and further fine-tuning.\n",
    "\n",
    "### ðŸŽ¯ **Why These Techniques?**  \n",
    "These methods collectively improve model robustness, reduce overfitting, and ensure the classifier can effectively guide the diffusion modelâ€”even in the presence of noise. The result is a high-performing model that aligns with the projectâ€™s goal of generating synthetic images under various camera settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from src.data import LensTypeDataset\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# CONFIGURATION & SETUP\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "SAVE_DIR = \"./checkpoints\"\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# ADVANCED DATA AUGMENTATION\n",
    "# ----------------------------\n",
    "def cutmix(images, labels, alpha=1.0):\n",
    "    \"\"\"Apply CutMix augmentation.\"\"\"\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(images.size(0)).to(device)\n",
    "    target_a, target_b = labels, labels[rand_index]\n",
    "\n",
    "    _, _, H, W = images.size()\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    cut_w, cut_h = int(W * np.sqrt(1 - lam)), int(H * np.sqrt(1 - lam))\n",
    "    x1, x2 = np.clip(cx - cut_w // 2, 0, W), np.clip(cx + cut_w // 2, 0, W)\n",
    "    y1, y2 = np.clip(cy - cut_h // 2, 0, H), np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    images[:, :, y1:y2, x1:x2] = images[rand_index, :, y1:y2, x1:x2]\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
    "    return images, target_a, target_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# DATA LOADERS\n",
    "# ----------------------------\n",
    "def get_loaders(batch_size, noise_probability=0.3, max_noise_std=0.4):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "    ])\n",
    "\n",
    "    train_dataset = LensTypeDataset(\"./data\", split=\"train\", transform=transform_train,\n",
    "                                     noisy_percentage=noise_probability, noise_stds=[max_noise_std])\n",
    "    val_dataset = LensTypeDataset(\"./data\", split=\"val\", transform=transform_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# MODEL DEFINITION\n",
    "# ----------------------------\n",
    "def build_model(hidden_units, dropout_rate):\n",
    "    model = models.efficientnet_b3(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    in_feats = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_feats, hidden_units),\n",
    "        nn.SiLU(inplace=True),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(hidden_units, 5)\n",
    "    )\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# TRAINING AND VALIDATION LOOPS\n",
    "# ----------------------------\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            images, target_a, target_b, lam = cutmix(images, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            if 'cutmix' in locals():\n",
    "                loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(train_loader.dataset), correct / len(train_loader.dataset)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(val_loader.dataset), correct / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# OPTUNA TUNING\n",
    "# ----------------------------\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
    "    dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.2, 0.5)\n",
    "    hidden_units = trial.suggest_categorical(\"hidden_units\", [256, 512, 1024])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "\n",
    "    train_loader, val_loader = get_loaders(batch_size=batch_size)\n",
    "    model = build_model(hidden_units, dropout_rate)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    scaler = torch.amp.GradScaler(device=device)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(10):\n",
    "        train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "        _, val_acc = validate(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best hyperparameters\n",
    "best_params = study.best_params\n",
    "torch.save(best_params, os.path.join(SAVE_DIR, \"best_hyperparams.pt\"))\n",
    "print(\"Best hyperparameters saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# FINAL TRAINING WITH METRIC TRACKING\n",
    "# ----------------------------\n",
    "def final_training(best_params, epochs=100, patience=10):\n",
    "    train_loader, val_loader = get_loaders(batch_size=best_params['batch_size'])\n",
    "    model = build_model(best_params['hidden_units'], best_params['dropout_rate'])\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    swa_model = AveragedModel(model)\n",
    "    swa_scheduler = SWALR(optimizer, swa_lr=best_params['lr'] / 2)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"best_model.pth\"))\n",
    "            print(f\"Best model saved with accuracy {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "\n",
    "    # Update Batch Norm Statistics using SWA Model\n",
    "    update_bn(train_loader, swa_model.to(device), device=device)  \n",
    "    torch.save(swa_model.state_dict(), os.path.join(SAVE_DIR, \"swa_model.pth\"))\n",
    "    print(\"âœ… SWA Model saved.\")\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"epoch\": list(range(1, len(train_losses) + 1)),\n",
    "        \"train_loss\": train_losses,\n",
    "        \"train_accuracy\": train_accuracies,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"val_accuracy\": val_accuracies\n",
    "    })\n",
    "    metrics_df.to_csv(os.path.join(OUTPUT_DIR, \"training_metrics.csv\"), index=False)\n",
    "    print(\"âœ… Training metrics saved to 'output/training_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run final training with saved best parameters\n",
    "best_params = torch.load(os.path.join(SAVE_DIR, \"best_hyperparams.pt\"))\n",
    "final_training(best_params, epochs=100, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# PLOTTING METRICS\n",
    "# ----------------------------\n",
    "metrics_df = pd.read_csv(os.path.join(OUTPUT_DIR, \"training_metrics.csv\"))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(metrics_df['epoch'], metrics_df['train_loss'], label='Train Loss')\n",
    "plt.plot(metrics_df['epoch'], metrics_df['val_loss'], label='Val Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(metrics_df['epoch'], metrics_df['train_accuracy'], label='Train Accuracy')\n",
    "plt.plot(metrics_df['epoch'], metrics_df['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
